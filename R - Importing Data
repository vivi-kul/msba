5 types of data sources: Flat files, Excel, Databases, Web, Statistical software (SAS, SPSS)

FLAT FILES (states.csv - Comma separated values)
Fields are separates by a comma
Fields will be columns in data frame
Records will be rows in data frame
Field names are used to give column names of data frame

UTILS package in R (loaded by default in R)
    read.csv("states.csv", stringsAsFactors = FALSE)
        Wrapper for CSV
        **IF set as FALSE, then variables will be strings, and not factors. MEANING they will ve CHARACTERS and not factors. 
        With stringsAsFactors, you can tell R whether it should convert strings in the flat file to factors.
        Default stringsasfactors is TRUE
        Default header = TRUE
        Default separator = ","
    If columns are strings, you can convert them into factors.
    Set it to false if strings should not be categorical dataframes.

What if file in datasets folder of home directory?
    path <- file.path("~", "datasets", "states.csv")
    "~/datasets/states.csv
    
For example, these two are the same:
    read.table("states.csv", header = TRUE, sep = ",", stringsasfactors = FALSE)
    read.csv("states.csv", stringsasfactors = FALSE)
    
TAB-DELIMITED FILES
    read.delim("states.txt",stringsasfactors = FALSE)
        Wrapper for tab-delimited files
        Default sep argument is "\t" (fields in a record are delimited by tabs) 
        Default header = TRUE (the first row contains the field names).
        
 For example, these 2 are the same:
    read.table("states.txt", header = TRUE, sep ="\t", stringsasfactors = FALSE)
    read.delim("states.txt", stringsasfactors = FALSE)
    
    read.table()
        Main function
        Read any tabular file as a data frame
        Number of arguments is huge
        Default header = FALSE
        Default sep argument is "".
       read.table("states2.txt", 
                  header = TRUE,  **first row will be variables names**
                  sep = "/", **specifies how fields in the file are separated"
                  stringsasfactors = FALSE) **False bc we want to import strings as strings**
                  
                 # Path to the hotdogs.txt file: path
                 path <- file.path("data", "hotdogs.txt")
                 
                 # Import the hotdogs.txt file: hotdogs
                 hotdogs <- read.table(path, 
                 sep = "\t", 
                 col.names = c("type", "calories", "sodium"))
                 
                 # Call head() on hotdogs
                 head(hotdogs)

# Finish the read.delim() call
    hotdogs <- read.delim("hotdogs.txt", header = FALSE, col.names = c("type", "calories", "sodium")) **if no header available, you can specify column names with col.names
# Select the hot dog with the least calories: lily
    lily <- hotdogs[which.min(hotdogs$calories), ] **which.min returns the index the smallest value in a vector
# Select the observation with the most sodium: tom
    tom <- hotdogs[which.max(hotdogs$sodium), ]
# Print lily and tom
    lily
    tom
    
You can specify column names, types, and classes.
    col.names
    colclasses (**useful if some should be factors and others characters** = no more stringsasfactors needed, 
                  if a column is set to NULL, then the column is skipped and not loaded into the df)
    coltype

read.delim("my_file.txt", 
           colClasses = c("character",
                          "numeric",
                          "logical"))

# Previous call to import hotdogs.txt
        hotdogs <- read.delim("hotdogs.txt", header = FALSE, col.names = c("type", "calories", "sodium"))
# Display structure of hotdogs
    str(hotdogs)
# Edit the colClasses argument to import the data correctly: hotdogs2
    hotdogs2 <- read.delim("hotdogs.txt", header = FALSE, 
                       col.names = c("type", "calories", "sodium"),
                       colClasses = c("factor", "NULL", "numeric"))
# Display structure of hotdogs2
    str(hotdogs2)
    
GO TO ?read.table to find more ways to import data and deal with regional differences and numbers
read.csv2 (can separate semicolons)
read.delim2

________________________________________________________________________________________________________________________________________________________________________

readr package
datatable package
read_csv
read_tsv

How to load readr package
install.packages("readr")
library(readr)

read_csv("states.csv")
Imports a data table
Strings are not imported as factors by default 

read_tsv (tab separated value)
Strings are not imported as factors by default 


utils package

read.table() - main utils function
read.csv()
read.delim()

readr package

read_delim() - main readr function
read_csv() **Assumes first row contains column names
read_tsv()

**USING CSV FUNCTION
# Load the readr package
    library(readr)
# Import potatoes.CSV with read_csv(): potatoes
    potatoes <- read_csv("potatoes.csv")

USING TSV FUNCTION
# readr is already loaded
# Column names
    properties <- c("area", "temp", "size", "storage", "method",
                "texture", "flavor", "moistness")
# Import potatoes.txt: potatoes
    potatoes <- read_tsv("potatoes.txt",col_names = properties)
# Call head() on potatoes
    head(potatoes)
    
USING DELIM FUNCTION
    read_delim("States.txt", delim ="/")
        Default header = TRUE (you could set col_names = FALSE if needed)
        Strings are not imported as factors by default
        Takes two mandatory arguments: file (the file containing the data), delim (the character that separates the values in the data file)
    Col_names is true by default
        read_delim("states3.txt", delim = "/", col_names = FALSE) **Returns X123 variables as colnames
        read_delim("states3.txt", delim = "/", col_names = c("state", "city", "pop", "area")
    Col_types
        Will be guessed from the first 30 rows
        Col types can be specified manually with col_types and a string
        read_delim("states2.txt", delim ="/", col_types = "ccdd")
        Use underscore to skip column
            If NULL then default from readr package will try to find types 
            Each character can denote the class of the column:
                c character
                d double
                i integer
                l logical
                _ skips the column as a whole
        
        # Import all data, but force all columns to be character: potatoes_char
         potatoes_char <- read_tsv("potatoes.txt", col_types = "cccccccc", col_names = properties)
   
   Skip and n_max
        Used for large datasets
        Skip specifies the number of lines you're ignoring in the flat file before actually starting to import data.
        Skip will also skip the header row, so you need to specify the column headers again
        read_delim("states2.txt", delim = "/", col_names = c("state", "city", "pop", "area"), skip = 2, n_max = 3)
        
        n_max specifies the number of lines you're actually importing.
        
        Through skip and n_max you can control which part of your flat file you're actually importing into R.
        Say for example you have a CSV file with 20 lines, and set skip = 2 and n_max = 3, you're only reading in lines 3, 4 and 5 of the file.

Watch out: Once you skip some lines, you also skip the first line that can contain column names

    Collector functions
        Another way of setting the types of the imported columns is using collectors. 
        Collector functions can be passed in a list() to the col_types argument of read_ functions to tell them how to interpret values in a column.
            col_integer(): the column should be interpreted as an integer.
            col_factor(levels, ordered = FALSE): the column should be interpreted as a factor with levels.
        
   # readr is already loaded
   # Column names
     properties <- c("area", "temp", "size", "storage", "method",
                "texture", "flavor", "moistness")
   # Import potatoes.txt using read_delim(): potatoes
     potatoes <- read_delim("potatoes.txt", delim= "\t", col_names = FALSE)
   # Print out potatoes
     potatoes
    
   # Import 5 observations from potatoes.txt: potatoes_fragment
     potatoes_fragment <- read_tsv("potatoes.txt", skip = 6, n_max = 5, col_names = properties)
   
   # Import all data, but force all columns to be character: potatoes_char
     potatoes_char <- read_tsv("potatoes.txt", col_types = "cccccccc", col_names = properties)
     
   # The collectors you will need to import the data
     fac <- col_factor(levels = c("Beef", "Meat", "Poultry"))
     int <- col_integer()
   # Edit the col_types argument to import the data correctly: hotdogs_factor
     hotdogs_factor <- read_tsv("hotdogs.txt", col_names = c("type", "calories", "sodium"), col_types = list(fac,int,int))
   # Display the summary of hotdogs_factor
     summary(hotdogs_factor)
     
     data.table
        function to import data: fread()
        
     install.packages("data.table")
     library(data.table)
        fread can infer column types and separators, and is really fast
        Possible to specify numerous parameters
        
     fread() had two arguments: drop and select, to drop or select variables of interest.
     Suppose you have a dataset that contains 5 variables and you want to keep the first and fifth variable, named "a" and "e":
        fread("path/to/file.txt", drop = 2:4)
        fread("path/to/file.txt", select = c(1, 5))
        fread("path/to/file.txt", drop = c("b", "c", "d"))
        fread("path/to/file.txt", select = c("a", "e"))
        
     # Import columns 6 and 8 of potatoes.csv: potatoes
        potatoes <- fread("potatoes.csv", select = c(6, 8))
     # Plot texture (x) and moistness (y) of potatoes
        plot(potatoes$texture, potatoes$moistness)
     
     The class of the result of fread() is both data.table and data.frame. 
     read_csv() creates an object with three classes: tbl_df, tbl and data.frame.
___________________________________________________________________________________________________________________________________________________________________________

READXL
     First familiarize yourself with the excel file, then import in R
    excel_sheets() - list different sheets
    read_excel() - actually import data into R (handles xls & xlxs files)
    
dir() reveals if file is already in our working directory
excel_sheets("city.xls") - just view different sheet names
read_excel("cities.xlsx", sheet = 2)
read_excel("cities.xlsx", sheet = "year_2000")
        
        data <- read_excel("data.xlsx", 
                            sheet = "my_sheet",
                            col_names = TRUE, (**TRUE is default and choses first row as header, character vector, manually specified, **R assigns names itself with FALSE))
                            col_types = NULL, 
                            skip = 0) (**skip = 2 would skip header and first row)

        data <- read_excel("cities.xlsx", 
                            col_types = c("text", "numeric", "date", "blank"))

# Load the readxl package
    library(readxl)
    dir() - view if its in directory
# Print the names of all worksheets
    excel_sheets("urbanpop.xlsx")

# Read the sheets, one by one
    pop_1 <- read_excel("urbanpop.xlsx", sheet = 1)
    pop_2 <- read_excel("urbanpop.xlsx", sheet = 2)
    pop_3 <- read_excel("urbanpop.xlsx", sheet = 3)
# Put pop_1, pop_2 and pop_3 in a list: pop_list
    pop_list <- list(pop_1, pop_2, pop_3)
# Display the structure of pop_list
    str(pop_list)
    
  USING LAPPLY
    my_workbook <- lapply(excel_sheets("data.xlsx"), read_excel, path = "data.xlsx")
    
# Read all Excel sheets with lapply(): pop_list
    pop_list <- lapply(excel_sheets("urbanpop.xlsx"),read_excel, path="urbanpop.xlsx")
# Display the structure of pop_list
    str(pop_list)

# Import the first Excel sheet of urbanpop_nonames.xlsx (specify col_names): pop_b
    cols <- c("country", paste0("year_", 1960:1966))
    pop_b <- read_excel("urbanpop_nonames.xlsx", col_names = cols)
# Print the summary of pop_b
    summary(pop_b)
    
# Import the second sheet of urbanpop.xlsx, skipping the first 21 rows: urbanpop_sel
    urbanpop_sel <- read_excel("urbanpop.xlsx", sheet = 2, col_names = FALSE, skip = 21)
# Print out the first observation from urbanpop_sel
    head(urbanpop_sel, n=1)
    urbanpop_sel[1, ]

GDATA package
    read.xls()
    Supports only xls
    support xlsx with additional driver
    Is an extension of the utils package
    
    xls -Perl- CSV -read.csv() - R data frame
                    - read.table(>15 arguments)
    It basically comes down to two steps: 
    (1) converting the Excel file to a .csv file using a Perl script, 
    (2) and then reading that .csv file with the read.csv() function that is loaded by default in R, through the utils package.

    install.packages("gdata")
    library(gdata)
    read.xls("cities.xls")
    
# Load the gdata package
    library(gdata)
# Import the second sheet of urbanpop.xls: urban_pop
    urban_pop <- read.xls("urbanpop.xls", sheet =2)
# Print the first 11 observations using head()
    head(urban_pop, n = 11)
    
# Column names for urban_pop
columns <- c("country", paste0("year_", 1967:1974))
# Finish the read.xls call
urban_pop <- read.xls("urbanpop.xls", sheet = 2,
                      skip = 50, header = FALSE, stringsAsFactors = FALSE,
                      col.names = columns)
# Print first 10 observation of urban_pop
head(urban_pop, n=10)

# Add code to import data from all three sheets in urbanpop.xls
    path <- "urbanpop.xls"
    urban_sheet1 <- read.xls(path, sheet = 1, stringsAsFactors = FALSE)
    urban_sheet2 <- read.xls(path, sheet = 2, stringsAsFactors = FALSE)
    urban_sheet3 <- read.xls(path, sheet = 3, stringsAsFactors = FALSE)
# Extend the cbind() call to include urban_sheet3: urban
    urban <- cbind(urban_sheet1, urban_sheet2[-1],urban_sheet3[-1])
# Remove all rows with NAs from urban: urban_clean
    urban_clean <- na.omit(urban)
# Print out a summary of urban_clean
    summary(urban_clean)
_______________________________________________________________________________________________________

XLCONNECT
    Working with excel files thru R
    Bridge between Excel and R
    Works with xls and xlsx files
    
    **To get a clear overview of file first, without opening it:
    my_book <- loadWorkbook("urbanpop.xlsx")
    sheets <- getSheets(my_book)
    all <- lapply(sheets, readWorksheet, object = my_book)
    str(all)
    
    install.packages("XLConnect")
    library("XLConnect")
    book <- loadWorkbook("cities.xlsx")
    str(book) - workbook object in R for class
    getsheets(book) - see sheets
    readWorksheet(book, sheet = "name"/index)
    
    readWorksheet(book, sheet ="year_2000", startrow=3, endrow=4, startcol=2, header=FALSE)
    
# Load the XLConnect package
    library(XLConnect)
# Build connection to urbanpop.xlsx: my_book
    my_book <- loadWorkbook("urbanpop.xlsx")
# Print out the class of my_book
    class(my_book)

# Build connection to urbanpop.xlsx
    my_book <- loadWorkbook("urbanpop.xlsx")
# List the sheets in my_book
    getSheets(my_book)
# Import the second sheet in my_book
    readWorksheet(my_book, sheet = 2)

# Build connection to urbanpop.xlsx
    my_book <- loadWorkbook("urbanpop.xlsx")
# Import columns 3, 4, and 5 from second sheet in my_book: urbanpop_sel
    urbanpop_sel <- readWorksheet(my_book, sheet = 2, startCol=3, endCol=5)
# Import first column from second sheet in my_book: countries
    countries <- readWorksheet(my_book, sheet = 2, startCol=1, endCol=1)
# cbind() urbanpop_sel and countries together: selection
    selection <- cbind(countries, urbanpop_sel)
    
ADAPTING DATA
    pop_2010 <- data.frame(Capital = c("New York", "Berlin", "Madrid", "Stockholm"), 
                Population = c(3323,2331,1223,1232))
    would create a df
    
    to start data in new sheet:
    pop_2010 <- ...
    library(XLConnect)
    book <- loadWorkbook("cities.xlsx")
    createSheet(book, name="year_2010")
    writeWorksheet(book, pop_2010, sheet="year_2010")
            writeWorksheet() takes three arguments: 
                the workbook, 
                the data you want to add, 
                and finally the sheet you want to add data to.
    saveWorkbook(book, file="cities2.xlsx") **needed to actually save and fill new worksheet, do new filename to not overwrite original sheet)
            saveWorkbook() takes two arguments: 
                the workbook 
                and the name of the Excel file you want to create as a string.
    renameSheet(book, "oldname","newname"
    then save again saveWorkbook(book, file="cities3.xlsx")
    removeSheet(book, sheet="Y2010")
    
How to create a new sheet
    my_book <- loadWorkbook("urbanpop.xlsx")
# Add a worksheet to my_book, named "data_summary"
    createSheet(my_book, name ="data_summary")
# Use getSheets() on my_book
    getSheets(my_book)
   
# Build connection to urbanpop.xlsx: my_book
    my_book <- loadWorkbook("urbanpop.xlsx")
# Rename "data_summary" sheet to "summary"
    renameSheet(my_book,"data_summary", "summary")
# Print out sheets of my_book
    getSheets(my_book)  
# Save workbook to "renamed.xlsx"
    saveWorkbook(my_book,file="renamed.xlsx")

# Load the XLConnect package
    library(XLConnect)
# Build connection to renamed.xlsx: my_book
    my_book <- loadWorkbook("renamed.xlsx")
# Remove the fourth sheet
    removeSheet(my_book, sheet=4)
# Save workbook to "clean.xlsx"
    saveWorkbook(my_book, file="clean.xlsx")
   
   
